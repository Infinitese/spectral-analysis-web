<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <title>Inharmonicity Analysis</title>

  <!-- ───── Global Styles ───── -->
  <style>
    :root {
      --bg:      #f9f9f9;
      --fg:      #333;
      --accent:  #2c3e50;
      --code-bg: #eee;
      --border:  #bbb;
    }

    /* base */
    body         { font-family: Arial, sans-serif; background: var(--bg); color: var(--fg); margin: 2rem; line-height: 1.6; }
    h1, h2, h3   { color: var(--accent); margin-top: 1.4rem; margin-bottom: .6rem; }
    h1           { font-size: 2rem; }
    h2           { font-size: 1.4rem; }
    h3           { font-size: 1.15rem; }
    p            { margin: .5rem 0 1rem; }
    .section     { margin-bottom: 2.2rem; }
    code, pre    { background: var(--code-bg); font-family: "Courier New", monospace; }
    code         { padding: 2px 4px; font-size: 90%; border-radius: 4px; }
    pre          { padding: .75rem 1rem; overflow-x: auto; border-radius: 6px; }

    /* media */
    img          { max-width: 620px; border: 1px solid #ccc; margin-bottom: 1.2rem; }
    audio        { margin: .3rem 0 1.2rem; width: 100%; max-width: 400px; }

    /* numeric table */
    .num-table      { border-collapse: collapse; margin: .5rem 0 1.2rem; }
    .num-table th,
    .num-table td   { border: 1px solid var(--border); padding: .25rem .6rem; text-align: right; }
    .num-table th   { background: #f2f2f2; }
    .num-table td:first-child,
    .num-table th:first-child { text-align: center; }

    /* simple call-outs */
    .formula    { margin: .6rem 0 .8rem; font-style: italic; }
    figure      { margin: .8rem 0 1.6rem; text-align: center; }
    figcaption  { font-size: 0.9rem; color: #666; margin-top: .4rem; }

    /* divider title */
    .divider-section {
      text-align: center;
      margin: 3em 0 2.5em;
    }

    .divider-title {
      display: inline-block;
      position: relative;
      font-size: 1.8em;
      padding: 0.5em 1em;
      background: var(--bg);
      color: var(--accent);
    }

    .divider-title::before,
    .divider-title::after {
      content: "";
      position: absolute;
      top: 50%;
      width: 50px;
      height: 1px;
      background: #ccc;
    }

    .divider-title::before {
      right: 100%;
      margin-right: 20px;
    }

    .divider-title::after {
      left: 100%;
      margin-left: 20px;
    }
    .result-block {
      background: var(--code-bg);
      font-family: "Courier New", monospace;
      padding: 0.8rem 1rem;
      border-radius: 6px;
      white-space: pre;          /* 保留空格缩进 */
      margin: 0.5rem 0 1.2rem;
    }
  </style>
</head>

<body>
  <h1>Inharmonicity Analysis</h1>

  <!-- 0. Overview -------------------------------------------------------- -->
  <section class="section">
    <h2>🔍 Project Overview</h2>
    <p>
      This page is just a start point by analysing a simple frame of vowel voice (<em>“ah”</em>) and estimate the fundamental frequency
      (<code>f₀</code>) and measure harmonic inharmonicity (<code>Δ<sub>k</sub></code>).
    </p>
  </section>

  <!-- 1. Audio ----------------------------------------------------------- -->
  <section class="section">
    <h2>🎧 Audio Sample</h2>
    <audio controls>
      <source src="A_PM66PSO5_a_190303153700.wav" type="audio/wav" />
      Your browser does not support the audio element.
    </audio>
  </section>

  <!-- Divider Title ----------------------------------------------------- -->
  <section class="divider-section">
    <h2 class="divider-title">Exploratory Analysis of a 20 ms Frame</h2>
  </section>

  <!-- 2. Waveforms ------------------------------------------------------- -->
  <section class="section">
    <h2>📈 Waveform of the 20 ms Frame</h2>
    <p>The extracted 20 ms frame (starting at 1 s):</p>
    <img src="extracted20ms.png" alt="20 ms frame waveform" />
  </section>

<section class="section">
  <h2>🧭 Frame Position in the Full Signal</h2>
  <p>The red segment shows where the 20 ms frame lies in the entire
     speech recording:</p>
  <img src="fullaudio.png" alt="Full waveform with highlighted frame" />
</section>

<!-- 3. Fundamental-frequency estimation -------------------------------- -->
<section class="section">
  <h2>🧮 Step 1 — Coarse Harmonic Residual Scan</h2>
  <p>
    A 500-point grid between <strong>50 Hz and 400 Hz</strong>
    is evaluated.  For each candidate we build an
    <code>8&nbsp;×&nbsp;N</code> harmonic matrix and record the residual
    energy <code>‖x − U a‖²</code>.  The global minimum is:
  </p>
  <pre><code>Coarse-scan f0 = 98.20 Hz
Coarse-scan w0 = 617.00 rad/s</code></pre>
  <p>(red marker in the residual plot below)</p>

  <figure>
    <img src="bestf0.png"   alt="Residual-energy curve" />
    <figcaption>Residual energy over 500 f₀ candidates.</figcaption>
  </figure>
</section>

<!--  STEP 2  ────────────────────────────────────────── -->
<section class="section">
  <h2>🎯 Step&nbsp;2 — Adaptive Harmonic-LS Refinement</h2>

  <p>
    The initial coarse scan merely shows <em>where</em>
    the global valley of the residual curve lies.
    To lock onto the exact minimum we run
    <code>estimate_omega0</code>
    <span class="ref">(Elvander &amp; Jakobsson 2020)</span>,
    which repeats the following loop until the search interval
    is&nbsp;&lt;&nbsp;<code>10⁻¹²&nbsp;rad/s</code> wide:
  </p>

  <ol>
    <li><strong>Bracket&nbsp;update</strong><br>
        Evaluate the cost on a 200-point grid inside the
        current interval <code>[ω<sub>L</sub>, ω<sub>H</sub>]</code>.</li>
    <li><strong>Narrowing</strong><br>
        Keep the best grid point and its two neighbours
        ⇒ new, shorter interval.</li>
    <li><strong>Re-grid</strong><br>
        Switch to a 50-point mesh for faster local convergence.</li>
  </ol>

  <ul>
    <li><strong>Harmonic order</strong>: K&nbsp;= 8</li>
    <li><strong>Initial interval</strong>: 50 Hz – 400 Hz</li>
    <li><strong>Cost function</strong>:
        <code>‖x – U(ω) (U(ω)\x)‖²</code></li>
  </ul>

  <pre><code>Refined f0 = 98.205 Hz
Refined w0 = 617.043 rad/s
Iterations  = 5 (≈ 7 ms on a laptop)</code></pre>

  <p>
    The refined <code>f₀ / w₀</code> serves as the harmonic
    baseline for the inharmonicity analysis in Step 3.
  </p>
</section>


<!-- 4. Inharmonicity analysis ----------------------------------------- -->
<!--  STEP 3 — OMT-prior Joint Estimation of Δk  -->
<section class="section">
  <h2>🎻 Step&nbsp;3 — OMT-prior Joint Estimation&nbsp;of&nbsp;Δ<sub>k</sub></h2>

  <!-- 3-A  WHY -->
  <p>
    A real voice is never perfectly harmonic: every partial can drift
    a few hertz due to <em>jitter</em>, vocal-tract interaction or
    measurement noise.  
    We therefore estimate <strong>all</strong> sinusoidal frequencies
    <code>ω̂<sub>k</sub></code> <em>and</em> the best global pitch
    <code>ω₀</code> in a single optimisation, using the
    <strong>Optimal&nbsp;Mass&nbsp;Transport&nbsp;(OMT) prior</strong>
    proposed by Elvander&nbsp;&amp;&nbsp;Jakobsson&nbsp;(2023).
  </p>

  <!-- 3-B  COST FUNCTION -->
  <h3> Cost function</h3>
  <p class="formula">
    <kbd>J(ω̂,a) = N · log ‖y − A(ω̂)a‖²
       + (1&nbsp;/&nbsp;2σ<sub>Δ</sub>²) · Σ<sub>k</sub>
         |a<sub>k</sub>|² (ω̂<sub>k</sub> − kω₀)²</kbd>
  </p>
  <ul>
    <li><code>A(ω̂)</code> — N × K harmonic matrix
        <code>e<sup>j k ω̂ t</sup></code></li>
    <li><code>a</code> — complex amplitudes (optimised together)</li>
    <li><code>ω₀&nbsp;≡&nbsp;ω₀(ω̂,a)</code>  
        &nbsp;= Σ|a<sub>k</sub>|² ω̂<sub>k</sub> /
        Σ|a<sub>k</sub>|² k² &nbsp;<!-- matches your omega0_func --></li>
    <li><code>σ<sub>Δ</sub> = 2 Hz</code> ⇒
        <code>λ = 1 / (2σ<sub>Δ</sub>²)</code></li>
  </ul>
  <p>
    The first term favours a close fit to the waveform,  
    the second pulls each partial toward its integer grid position
    <code>k·ω₀</code> with a quadratic “transport” cost.
  </p>

  <!-- 3-C  OPTIMISATION PROCEDURE -->
  <h3> Optimisation procedure</h3>
  <ol>
    <li><b>Initial guess</b>: perfectly harmonic grid
        <code>ω̂<sub>k,0</sub> = k·ω₀<sub>LS</sub></code>.</li>
    <li><b>Parameter vector</b>:
        <code>[ ω̂<sub>1:K</sub>, Re{a}<sub>1:K</sub>,
                Im{a}<sub>1:K</sub> ] → 3K&nbsp;dims</code>.</li>
    <li><b>Solver</b>: Nelder–Mead
        (<code>fminsearch</code>, tol = 10<sup>-10</sup>).  
        Converges in&nbsp;≈ 30–50 iterations for a 20 ms frame.</li>
  </ol>

  <!-- 3-D  NUMERIC RESULTS (table stays the same) -->
  <h3> Numerical results</h3>
  <p>
    <strong>f<sub>0,LS</sub> = 98.205 Hz</strong> |
    <strong>f<sub>0,OMT</sub> = 98.181 Hz</strong>
    (<em>difference 0.025 Hz</em>)
  </p>

  <table class="num-table">
    <thead>
      <tr>
        <th>k</th><th>ω̂<sub>k</sub> (Hz)</th>
        <th>k·f<sub>0,OMT</sub> (Hz)</th>
        <th>Δ<sub>k</sub> (Hz)</th>
      </tr>
    </thead>
    <tbody>
      <tr><td>1</td><td>101.846</td><td>98.181</td><td>+3.673</td></tr>
      <tr><td>2</td><td>194.872</td><td>196.362</td><td>−1.496</td></tr>
      <tr><td>3</td><td>294.725</td><td>294.544</td><td>+0.191</td></tr>
      <tr><td>4</td><td>390.122</td><td>392.725</td><td>−2.600</td></tr>
      <tr><td>5</td><td>488.501</td><td>490.906</td><td>−2.401</td></tr>
      <tr><td>6</td><td>590.860</td><td>589.087</td><td>+1.780</td></tr>
      <tr><td>7</td><td>684.763</td><td>687.269</td><td>−2.508</td></tr>
      <tr><td>8</td><td>786.328</td><td>785.450</td><td>+0.888</td></tr>
    </tbody>
  </table>

  <!-- 3-E  DERIVED METRICS / PLOT -->
  <h3> Derived metrics</h3>
  <ul>
    <li><b>OMT cost</b>: 6.10 × 10<sup>2</sup></li>
  </ul>

  <figure>
    <img src="deviation.png" alt="Stem plot of Δ_k (Hz)">
    <figcaption>
      Δ<sub>k</sub> stem plot: peak-to-peak ±4 Hz, alternating sign —
      typical of short-term jitter rather than physical string inharmonicity.
    </figcaption>
  </figure>
</section>

<!-- Divider Title ----------------------------------------------------- -->
<section class="divider-section">
  <h2 class="divider-title">Sliding Window Analysis of Multiple Audios</h2>
</section>

<!-- Sliding Window Analysis ==================================================== -->


<section class="section">
  <h3>📝 Method Recap</h3>
  <p>
    For each recording we slide a <strong>20&nbsp;ms frame</strong> with a
    <strong>10&nbsp;ms hop</strong>. Each frame’s fundamental frequency
    (<code>f₀</code>) and inharmonic offsets
    (<code>Δ<sub>k</sub></code>, k = 1–8) are estimated via the
    OMT-based routine established earlier. After discarding unvoiced or
    abnormal frames (<em>f₀</em> &lt; 80 Hz or &gt; 300 Hz), we summarize
    every recording by the mean and standard deviation of each
    <code>Δ<sub>k</sub></code>.
  </p>
</section>

<section class="section">
  <p><em>For brevity, only the first recording per speaker is shown below.</em></p>
</section>

<!-- Speaker 1 ========================================================= -->
<section class="section">
  <h3>🗣️ Speaker 1 | 10 recordings</h3>
  <details open>
    <summary>Recording 1 (<code>Recording1.wav</code>)</summary>
    <pre class="result-block">
Valid voiced frames : 212
Mean f0 (OMT)       :  88.23 ±  3.13  Hz
Per-harmonic statistics (Hz)
 k |  mean  |   std
---+--------+--------
 1 |   7.59 |   5.91
 2 |   5.81 |  16.92
 3 |  -6.31 |  24.56
 4 |  -4.48 |  26.80
 5 |   2.97 |  17.62
 6 |   2.07 |  15.52
 7 |  -1.50 |   7.30
 8 |   0.71 |  15.12
    </pre>
  </details>
</section>

<!-- Speaker 2 ========================================================= -->
<section class="section">
  <h3>🗣️ Speaker 2 | 3 recordings</h3>
  <details open>
    <summary>Recording 1 (<code>Recording1.wav</code>)</summary>
    <pre class="result-block">
Valid voiced frames : 271
Mean f0 (OMT)       : 139.05 ±  1.18  Hz
Per-harmonic statistics (Hz)
 k |  mean  |   std
---+--------+--------
 1 |  -0.22 |   3.44
 2 |   1.73 |   7.71
 3 |  -2.71 |  14.99
 4 |  -2.10 |  32.61
 5 |  -0.75 |   9.03
 6 |  -1.49 |  13.90
 7 |  11.15 | 114.17
 8 |  14.53 | 163.79
    </pre>
  </details>
</section>

<!-- Speaker 3 ========================================================= -->
<section class="section">
  <h3>🗣️ Speaker 3 | 3 recordings</h3>
  <details open>
    <summary>Recording 1 (<code>Recording1.wav</code>)</summary>
    <pre class="result-block">
Valid voiced frames : 255
Mean f0 (OMT)       : 177.51 ±  0.86  Hz
Per-harmonic statistics (Hz)
 k |  mean  |   std
---+--------+--------
 1 |   0.13 |   3.10
 2 |   0.54 |  13.50
 3 |  -0.26 |  10.00
 4 |   0.07 |   1.11
 5 |   5.96 |  18.15
 6 |  -1.03 |   5.85
 7 |   0.80 |   9.08
 8 |   5.83 |  62.08
    </pre>
  </details>
</section>


<!-- ==================================================================== -->
<section class="divider-section">
  <h2 class="divider-title">Across-Recording &amp; Across-Speaker Summary</h2>
</section>

<section class="section">
  <h3>📊 Per-Speaker Summary Table</h3>
  <p>
    For each harmonic index <code>k</code> (rows 1 – 8) we report:
    <ul>
      <li><code>μ<sub>spk<i>n</i></sub></code> – mean offset
          <code>Δ<sub>k</sub></code> (Hz) averaged over all recordings
          of speaker <em>n</em>.</li>
      <li><code>SD<sub>rec_spk<i>n</i></sub></code> – within-speaker
          standard deviation of <code>Δ<sub>k</sub></code>
          across that speaker’s recordings.  
          It captures <em>intra-speaker</em> variability.</li>
    </ul>
  </p>

  <pre class="result-block">
k   μ_spk1   SDrec_spk1   μ_spk2   SDrec_spk2   μ_spk3   SDrec_spk3
-------------------------------------------------------------------
1   3.6786     3.0193     0.3993     0.6963     -0.1096     1.0101
2   4.0347     3.4948     0.7806     3.0569      0.4869     0.7744
3  -2.9694     2.8742    -2.0519     0.8076     -1.2760     4.6265
4   4.8555     4.2508    -0.1398     1.7007      0.2078     0.6943
5   2.2493     3.5137    -3.2077     3.0201      2.5803     2.9715
6   2.4613     4.3686    -2.2537     2.7328     -0.9323     0.9221
7  -3.1748     3.1321     3.4347     6.6808      0.5584     1.6450
8  -1.5673     2.1176    18.2900    14.6190      2.5191     4.3416
  </pre>
</section>

<section class="section">
  <h3>🌐 Overall Summary Table</h3>
  <p>
    Collapsing the three speakers we compute:
    <ul>
      <li><code>μ̄<sub>k</sub></code> – grand mean of
          <code>Δ<sub>k</sub></code> over <em>all</em> recordings
          (i.e.&nbsp;averaged first within, then across speakers).</li>
      <li><code>SD<sub>rec_mean</sub></code> – mean of
          within-speaker SDs (<code>SD<sub>rec</sub></code>)
          ⇒ typical <em>record-to-record</em> fluctuation.</li>
      <li><code>SD<sub>spk</sub></code> – standard deviation of the three
          speaker means ⇒ <em>inter-speaker</em> spread.</li>
    </ul>
  </p>

  <pre class="result-block">
k   μ̄_k    SD_rec_mean   SD_spk
-------------------------------
1  1.3227     1.5753     2.0560
2  1.7674     2.4420     1.9691
3 -2.0991     2.7694     0.8477
4  1.6412     2.2153     2.7891
5  0.5407     3.1684     3.2504
6 -0.2415     2.6745     2.4322
7  0.2728     3.1893     3.3134
8  6.4138     7.0260    10.4860
  </pre>
</section>

<!-- ==================================================================== -->
<section class="section">
  <h3>📊 Visual Comparison of Offset Metrics</h3>
  <p>
    The three visuals below summarise how each speaker’s inharmonic offsets
    behave in terms of <em>direction</em> (mean&nbsp;μ<sub>k</sub>) and
    <em>stability</em> (standard deviation&nbsp;σ<sub>k</sub> / within-recording
    jitter).  Scroll through the panels for a step-by-step interpretation.
  </p>
</section>

<!-- ──────────────────────────────────────────────────────────────────── -->
<section class="section">
  <h4>① Mean deviation&nbsp;μ<sub>k</sub> across speakers</h4>
  <p>
    Positive values indicate upward shifts from perfect harmonics;
    negatives indicate downward shifts.
  </p>

  <img src="mu_k across speakers.png"
       alt="Line chart comparing μ_k for three speakers"
       style="max-width: 720px; border: 1px solid #bbb; margin-bottom: 1rem;" />

  <p><strong>Key observations</strong>:</p>
  <ul>
    <li><b>k = 1–2</b>: Speaker&nbsp;1 ≈ +4 Hz, Speakers 2–3 ≈ +1 Hz → low-order
        harmonics separate Spk1 from the others.</li>
    <li><b>k = 3</b>: All speakers drop ≈ –2 Hz → shared inharmonicity trend.</li>
    <li><b>k = 8</b>: Speaker 2 reaches +18 Hz → high-order harmonic highlights
        a speaker-specific trait.</li>
  </ul>
  <p><em>Conclusion:</em> Only the bottom two and top one harmonics provide clear
  speaker discrimination; mid-band harmonics show little systematic ranking.</p>
</section>

<!-- ──────────────────────────────────────────────────────────────────── -->
<section class="section">
  <h4>② Variability&nbsp;σ<sub>k</sub> (offset SD) across speakers</h4>
  <p>
    σ<sub>k</sub> measures <em>how much</em> the offset fluctuates within a
    speaker’s recordings.
  </p>

  <img src="sigma_k across speakers.png"
       alt="Line chart comparing σ_k (offset SD) for three speakers"
       style="max-width: 720px; border: 1px solid #bbb; margin-bottom: 1rem;" />

  <p><strong>Key observations</strong>:</p>
  <ul>
    <li><b>k = 1–4</b>: All speakers stable (σ ≈ 2–5 Hz).</li>
    <li><b>k = 6–7</b>: Small divergence, but still &lt; 4 Hz.</li>
    <li><b>k = 8</b>: Speaker 2 σ₈ ≈ 15 Hz ≫ others → high-order harmonic
        both biased <em>and</em> unstable for Spk2.</li>
  </ul>
  <p><em>Conclusion:</em> Stability is largely recording-driven except at the
  8-th harmonic, where speaker identity dominates.</p>
</section>

<!-- ──────────────────────────────────────────────────────────────────── -->
<section class="section">
  <h4>③  Within-speaker jitter across harmonics (k = 1–4)</h4>
  <p>
    For each speaker we plot one box per harmonic (<strong>k = 1–4</strong>).
    A box summarises the distribution of σ<sub>k</sub> taken across that
    speaker’s multiple recordings, therefore illustrating <em>how unstable
    each harmonic is for that talker</em>.
    The x-axis is the harmonic index <code>k</code>, not the recording ID.
  </p>

  <img src="3speakers boxchart.png"
       alt="Boxplots of σ_k (k=1–4) per speaker"
       style="max-width: 940px; border: 1px solid #bbb; margin-bottom: 1rem;" />

  <p><strong>Key observations</strong>:</p>
  <ul>
    <li><b>k = 1–2</b>: All speakers remain relatively stable
        (σ&nbsp;&lt;&nbsp;10 Hz), indicating low-order harmonics are least
        affected by recording variability.</li>

    <li><b>k = 3</b>: Variability starts to diverge—Speaker 1 already exceeds
        15 Hz, while Speakers 2&nbsp;and 3 stay below that threshold.</li>

    <li><b>k = 4</b>: Jitter spikes for everyone, but most dramatically
        for <b>Speaker 1</b> (whisker&nbsp;&gt;&nbsp;48 Hz) and
        <b>Speaker 2</b> (median&nbsp;≈ 30 Hz).  This confirms that the 4-th
        harmonic is intrinsically more sensitive to vocal or environmental
        fluctuations.</li>
  </ul>

  <p>
    <em>Conclusion:</em> Low-order jitter is harmonic-dependent: while
    k = 1–2 are uniformly stable, k = 4 becomes highly volatile, with Speaker
    differences amplified.  Before attributing offsets to physiology, the
    4-th harmonic demands stricter recording control or additional smoothing.
  </p>
</section>

<!-- =============================================================== -->
<section class="divider-section">
  <h2 class="divider-title">Frame concatenation for exploring Δ<sub>k</sub></h2>
</section>

<section class="section">
  <p>
    In previous sections, we observed that the stability of offset metrics (Δ<sub>k</sub>) can vary by harmonic order,
    especially in the higher harmonics. But are these differences in variability statistically significant?
    Are these patterns aligns with some specific statistic models? To answer this, we first try to find a distribution among the data.
  </p>
  <p>
    Since each individual  only has a limited number of recordings, we concatenate all recordings for each speaker, which means we 
    treat each frame as a separate data, rather than a recording - although this approach may not take into account the differences 
    between recordings, but just try it out now.This gives us over hundred to thousand frame-level Δ<sub>k</sub> observations</strong> 
    per speaker — maybe sufficient to perform statistical models.
  </p>

  <p>
    I have combined the offset calculation data of all frames of each person's recording, and the relevant data is saved in the attachment. 
    At each harmonic, spk1 has more than 3000 data points, spk2 and spk3 have about 700 data points each.
    Let's take the case of k=1 as an example and draw a scatter plot of the data of three people.
  </p>
</section>

<!-- ===== Scatter plots (images) for Δk by speaker ===== -->
<section class="section">
  <h3>Scatter plots of Δ<sub>k</sub> (per frame) for three speakers</h3>

  <img src="spk1_k1.png"
       alt="Scatter plot of Δk vs frame index for spk1"
       style="max-width: 720px; border: 1px solid #bbb; margin-bottom: 1rem;" />

  <img src="spk2_k1.png"
       alt="Scatter plot of Δk vs frame index for spk2"
       style="max-width: 720px; border: 1px solid #bbb; margin-bottom: 1rem;" />

  <img src="spk3_k1.png"
       alt="Scatter plot of Δk vs frame index for spk3"
       style="max-width: 720px; border: 1px solid #bbb; margin-bottom: 1rem;" />

  <p>
    From the scatter plots, <strong>spk1</strong> and <strong>spk3</strong> look relatively stable across frames.
    In contrast, <strong>spk2</strong> shows a pronounced deviation in the middle segment, which likely stems from
    an anomalous recording. To avoid bias, we will temporarily exclude <strong>spk2</strong> and build models using
    <strong>spk1</strong> and <strong>spk3</strong> only.
  </p>
</section>

</body>
</html>

